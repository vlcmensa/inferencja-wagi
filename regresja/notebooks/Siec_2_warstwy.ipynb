{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b41d93a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T14:16:54.869294Z",
     "iopub.status.busy": "2025-09-26T14:16:54.869294Z",
     "iopub.status.idle": "2025-09-26T14:17:33.168357Z",
     "shell.execute_reply": "2025-09-26T14:17:33.167356Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "596d9564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing MNIST datasets (torchvision)...\n",
      "Device: cpu\n",
      "Train batches: 235, Test batches: 40\n"
     ]
    }
   ],
   "source": [
    "# Prepare torchvision MNIST datasets and loaders\n",
    "print(\"Preparing MNIST datasets (torchvision)...\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),            # [0,1]\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # standard MNIST normalization\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"data/MNIST\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"data/MNIST\", train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "input_dim = 28 * 28\n",
    "num_classes = 10\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Train batches: {len(train_loader)}, Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d1f1d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview a few images from the DataLoader\n",
    "np.set_printoptions(linewidth=200, threshold=784, suppress=True)\n",
    "\n",
    "examples, labels = next(iter(train_loader))\n",
    "fig, axes = plt.subplots(1, 6, figsize=(10, 2))\n",
    "for i in range(6):\n",
    "    axes[i].imshow(examples[i, 0].numpy(), cmap='gray')\n",
    "    axes[i].set_title(int(labels[i]))\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa744d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTLinear(\n",
      "  (net): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a logistic-regression-like network: input -> output (no hidden layers)\n",
    "class MNISTLinear(nn.Module):\n",
    "    def __init__(self, input_dim: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MNISTLinear(input_dim=input_dim, num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe47270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [100/235] Loss: 0.7550\n",
      "Epoch 1 [200/235] Loss: 0.3815\n",
      "Epoch 1 training accuracy: 84.95%\n",
      "Epoch 1 test accuracy: 91.00%\n",
      "Epoch 2 [100/235] Loss: 0.3254\n",
      "Epoch 2 [200/235] Loss: 0.3115\n",
      "Epoch 2 training accuracy: 91.00%\n",
      "Epoch 2 test accuracy: 91.68%\n",
      "Epoch 3 [100/235] Loss: 0.3033\n",
      "Epoch 3 [200/235] Loss: 0.2865\n",
      "Epoch 3 training accuracy: 91.68%\n",
      "Epoch 3 test accuracy: 92.29%\n",
      "Epoch 4 [100/235] Loss: 0.2783\n",
      "Epoch 4 [200/235] Loss: 0.2915\n",
      "Epoch 4 training accuracy: 91.98%\n",
      "Epoch 4 test accuracy: 91.99%\n",
      "Epoch 5 [100/235] Loss: 0.2689\n",
      "Epoch 5 [200/235] Loss: 0.2791\n",
      "Epoch 5 training accuracy: 92.32%\n",
      "Epoch 5 test accuracy: 91.97%\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "num_epochs = 5  # liczba epok treningu\n",
    "log_interval = 100  # co ile batchy logować średnią stratę\n",
    "\n",
    "train_losses = []  # historia strat treningowych (tu nie jest wypełniana)\n",
    "train_accuracies = []  # historia dokładności treningowych w %\n",
    "test_accuracies = []  # historia dokładności testowych w %\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):  # pętla po epokach\n",
    "    model.train()  # przełącz model w tryb treningu\n",
    "    correct = 0  # licznik trafnych przewidywań (train)\n",
    "    total = 0  # licznik wszystkich przykładów (train)\n",
    "    running_loss = 0.0  # akumulacja straty do logowania\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader, start=1):  # pętla po batchach treningowych\n",
    "        inputs = inputs.to(device)  # przenieś obrazy na CPU/GPU\n",
    "        targets = targets.to(device)  # przenieś etykiety na CPU/GPU\n",
    "\n",
    "        optimizer.zero_grad()  # wyzeruj zebrane gradienty\n",
    "        outputs = model(inputs)  # przód: oblicz logity dla batcha\n",
    "        loss = criterion(outputs, targets)  # policz stratę (np. CrossEntropyLoss)\n",
    "        loss.backward()  # wstecz: policz gradienty\n",
    "        optimizer.step()  # zaktualizuj wagi modelu\n",
    "\n",
    "        running_loss += loss.item()  # dodaj bieżącą stratę do sumy\n",
    "        _, predicted = outputs.max(1)  # argmax po klasach = przewidziana klasa\n",
    "        total += targets.size(0)  # zwiększ licznik przykładów\n",
    "        correct += predicted.eq(targets).sum().item()  # zwiększ licznik trafień\n",
    "\n",
    "        if batch_idx % log_interval == 0:  # co N batchy wypisz średnią stratę\n",
    "            print(f\"Epoch {epoch} [{batch_idx}/{len(train_loader)}] Loss: {running_loss/log_interval:.4f}\")  # log\n",
    "            running_loss = 0.0  # reset akumulatora straty\n",
    "\n",
    "    train_acc = 100.0 * correct / total  # dokładność treningowa w %\n",
    "    train_accuracies.append(train_acc)  # zapisz dokładność do historii\n",
    "    print(f\"Epoch {epoch} training accuracy: {train_acc:.2f}%\")  # wypisz wynik treningu\n",
    "\n",
    "\n",
    "    model.eval()  # przełącz model w tryb ewaluacji\n",
    "    correct = 0  # reset trafień (test)\n",
    "    total = 0  # reset liczby przykładów (test)\n",
    "    with torch.no_grad():  # bez śledzenia gradientów (szybciej, oszczędniej)\n",
    "        for inputs, targets in test_loader:  # pętla po batchach testowych\n",
    "            inputs = inputs.to(device)  # przenieś obrazy na CPU/GPU\n",
    "            targets = targets.to(device)  # przenieś etykiety na CPU/GPU\n",
    "            outputs = model(inputs)  # przewidywania dla testu\n",
    "            _, predicted = outputs.max(1)  # klasa o najwyższym wyniku\n",
    "            total += targets.size(0)  # zwiększ licznik przykładów (test)\n",
    "            correct += predicted.eq(targets).sum().item()  # zwiększ trafienia (test)\n",
    "    test_acc = 100.0 * correct / total  # dokładność testowa w %\n",
    "    test_accuracies.append(test_acc)  # zapisz do historii\n",
    "    print(f\"Epoch {epoch} test accuracy: {test_acc:.2f}%\")  # wypisz wynik testu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00efd997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weights to outputs\\mnist_mlp.pth\n",
      "Exported ONNX to outputs\\mnist_mlp.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_18872\\2337890801.py:12: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    }
   ],
   "source": [
    "# Save model and export ONNX\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "pth_path = os.path.join(\"outputs\", \"mnist_mlp.pth\")\n",
    "torch.save(model.state_dict(), pth_path)\n",
    "print(f\"Saved weights to {pth_path}\")\n",
    "\n",
    "# Export to ONNX\n",
    "onnx_path = os.path.join(\"outputs\", \"mnist_mlp.onnx\")\n",
    "model_cpu = model.to(\"cpu\").eval()\n",
    "dummy = torch.randn(1, 1, 28, 28)\n",
    "torch.onnx.export(\n",
    "    model_cpu,\n",
    "    dummy,\n",
    "    onnx_path,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch\"}, \"logits\": {0: \"batch\"}},\n",
    "    opset_version=13\n",
    ")\n",
    "print(f\"Exported ONNX to {onnx_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52eb688f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# Predict digit from test2.png, display centered 20x20 on 28x28 and print predicted digit\n",
    "img_path = \"test2.png\"\n",
    "model_path = os.path.join(\"outputs\", \"mnist_mlp.pth\")  # reuse existing weights filename\n",
    "\n",
    "# Fallback: define MNISTLinear if not present (matches current definition)\n",
    "try:\n",
    "    MNISTLinear\n",
    "except NameError:\n",
    "    class MNISTLinear(nn.Module):\n",
    "        def __init__(self, input_dim: int, num_classes: int):\n",
    "            super().__init__()\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(input_dim, num_classes)\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.net(x)\n",
    "\n",
    "if not os.path.exists(img_path):\n",
    "    raise FileNotFoundError(\"test2.png not found\")\n",
    "\n",
    "# Load, convert to grayscale, resize to 20x20\n",
    "img_orig = Image.open(img_path).convert(\"L\")\n",
    "img_20 = img_orig.resize((20, 20), resample=Image.BILINEAR)\n",
    "\n",
    "# Create 28x28 black canvas and center the 20x20 digit\n",
    "canvas = Image.new(\"L\", (28, 28), color=0)  # black background like MNIST\n",
    "offset = ((28 - 20) // 2, (28 - 20) // 2)  # (4, 4)\n",
    "canvas.paste(img_20, offset)\n",
    "\n",
    "# Show processed image\n",
    "plt.figure(figsize=(2.5, 2.5))\n",
    "plt.imshow(canvas, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Preprocess for model\n",
    "to_tensor = transforms.ToTensor()\n",
    "tensor = to_tensor(canvas)  # -> [0,1], (1,28,28)\n",
    "# Auto-invert if background looks white\n",
    "if tensor.mean().item() > 0.5:\n",
    "    tensor = 1.0 - tensor\n",
    "normalize = transforms.Normalize((0.1307,), (0.3081,))\n",
    "tensor = normalize(tensor).unsqueeze(0)  # (1,1,28,28)\n",
    "\n",
    "# Load model and predict\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(\"Model weights not found. Train and save first.\")\n",
    "model_cpu = MNISTLinear(input_dim=28*28, num_classes=10)\n",
    "state = torch.load(model_path, map_location=\"cpu\")\n",
    "model_cpu.load_state_dict(state)\n",
    "model_cpu.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model_cpu(tensor)\n",
    "    pred = int(logits.argmax(dim=1).item())\n",
    "\n",
    "# Print prediction under the image\n",
    "plt.title(f\"Predicted: {pred}\")\n",
    "plt.show()\n",
    "print(pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
